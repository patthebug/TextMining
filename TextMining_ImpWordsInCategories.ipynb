{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import nltk\n",
      "import re\n",
      "from numpy import matrix\n",
      "from sklearn.datasets import load_files\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "import numpy as np\n",
      "import os\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from nltk.corpus import wordnet\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from random import randrange\n",
      "from nltk.stem.snowball import SnowballStemmer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I tried porter stemmer but found that SnowballStemmer performs better than porter stemmer\n",
      "stemmer = SnowballStemmer('english')\n",
      "\n",
      "def stem_tokens(tokens, stemmer):\n",
      "    stemmed = []\n",
      "    for item in tokens:\n",
      "        if len(item) <= 2:\n",
      "            continue\n",
      "        else:\n",
      "            if(wordnet.synsets(item)):\n",
      "                stemmed.append(stemmer.stem(item))\n",
      "    return stemmed\n",
      "\n",
      "# I am only accepting words which start with an alphabet\n",
      "def tokenize(text):\n",
      "#     tokenizer = RegexpTokenizer('[A-Za-z]\\w+([A-za-z]|\\d)')\n",
      "    tokenizer = RegexpTokenizer('[A-Za-z]\\w+')\n",
      "    tokens = tokenizer.tokenize(text)\n",
      "    stems = stem_tokens(tokens, stemmer)\n",
      "    return stems"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers','quotes'))\n",
      "vectorizer = TfidfVectorizer(min_df=5, stop_words='english',tokenizer=tokenize)\n",
      "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
      "categories = newsgroups_train.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In the following code, I am trying to calculate the mean of every single column in the matrix. The code takes 100 random\n",
      "# documents from every category the performs the mean calculation\n",
      "# I spent many hours working on it without using .toarray() function but somehow could not make it work.\n",
      "# I also calculated median instead of mean but the results did not make a lot of sense and therefore I persisted with mean.\n",
      "# The following code is pretty fast and uses .toarray() only on a subset of data.\n",
      "# Here's the code that I used for median:\n",
      "\n",
      "# y = np.ma.masked_where(X_train[sample[0]].toarray() == 0, X_train[sample[0]].toarray())\n",
      "#     medArray = np.ma.median(y, axis=0).filled(0)\n",
      "#     print '============median ' + newsgroups_train.target_names[i] + '============='\n",
      "#     for k,word in enumerate(np.array(vectorizer.get_feature_names())[np.argsort(medArray)[::-1][0:10]]):\n",
      "#         print word + ':' + str(np.sort(medArray)[::-1][k])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(categories)):    \n",
      "    sample = [] \n",
      "    idx = matplotlib.mlab.find(newsgroups_train.target==i)\n",
      "    random_index = []\n",
      "    \n",
      "    for j in range(100):\n",
      "        random_index.append(randrange(0,len(idx)-1)) \n",
      "        \n",
      "    sample.append(idx[random_index])\n",
      "    \n",
      "    meanArray = np.mean(X_train[sample[0]].toarray(), axis=0)\n",
      "    print '============' + newsgroups_train.target_names[i] + '============='\n",
      "    \n",
      "    for j,word in enumerate(np.array(vectorizer.get_feature_names())[np.argsort(meanArray)[::-1][0:10]]):\n",
      "        print word + ':' + str(np.sort(meanArray)[::-1][j])\n",
      "\n",
      "#     for j,word in enumerate(np.array(vectorizer.get_feature_names())[np.argsort(meanArray)[::-1][0:10]]):\n",
      "#         print word + ':' + str(np.sort(meanArray)[::-1][j])\n",
      "        \n",
      "# The following code is just hit n trial and something I wrote when I was trying to get the most out of numpy.\n",
      "        \n",
      "#     print count\n",
      "#     indices = np.random.randint(count, len(os.listdir(filepath+ '/home/patthebug/PycharmProjects/TextMining_Assignment3/datasets/20news-bydate-train/' + category)) + count - 1, 200)\n",
      "#     count += len(os.listdir(filepath+ '/home/patthebug/PycharmProjects/TextMining_Assignment3/datasets/20news-bydate-train/' + category))\n",
      "#     tempArray = X_train[indices].toarray()\n",
      "        \n",
      "#     print indices\n",
      "#     print len(tempArray[0])\n",
      "#     print tempArray[0,np.nonzero(tempArray[0])]\n",
      "#     print len(tempArray[0].shape)\n",
      "#     print type(tempArray)\n",
      "    \n",
      "#     for i in range(len(tempArray)):\n",
      "#         arrayForMedian = np.nonzero(tempArray[i])\n",
      "#         print np.median(tempArray[i,arrayForMedian], axis=0)\n",
      "      \n",
      "#     for i in range(len(tempArray[0])):\n",
      "#     print np.nonzero(tempArray)\n",
      "#     print np.median(tempArray[np.nonzero(tempArray)], axis=0)\n",
      "#     meanArray = np.mean(tempArray, axis=0)\n",
      "# #     meanArray = np.sort(meanArray)[::-1][0:10]\n",
      "#     print '============mean ' + category + '============='\n",
      "#     for i,word in enumerate(np.array(vectorizer.get_feature_names())[np.argsort(meanArray)[::-1][0:10]]):\n",
      "#         print word + ':' + str(np.sort(meanArray)[::-1][i])\n",
      "#     print sample \n",
      "#     meanArray = np.mean(sample, axis=0)\n",
      "#     print np.array(sample[0]).shape\n",
      "# #     meanArray = np.sort(meanArray)[::-1][0:10]\n",
      "#     print '============mean ' + category + '============='\n",
      "#     for i,word in enumerate(np.array(vectorizer.get_feature_names())[np.argsort(meanArray)[::-1][0:10]]):\n",
      "#         print word + ':' + str(np.sort(meanArray)[::-1][i])\n",
      "        \n",
      "#     y = np.ma.masked_where(X_train[indices].toarray() == 0, X_train[indices].toarray())\n",
      "#     medArray = np.ma.median(y, axis=0).filled(0)\n",
      "#     print '============median ' + category + '============='\n",
      "#     for i,word in enumerate(np.array(vectorizer.get_feature_names())[np.argsort(medArray)[::-1][0:10]]):\n",
      "#         print word + ':' + str(np.sort(medArray)[::-1][i])\n",
      "        \n",
      "#     y = np.ma.masked_where(X_train[sample[0]].toarray() == 0, X_train[sample[0]].toarray())\n",
      "#     medArray = np.ma.median(y, axis=0).filled(0)\n",
      "#     print '============median ' + newsgroups_train.target_names[i] + '============='\n",
      "#     for k,word in enumerate(np.array(vectorizer.get_feature_names())[np.argsort(medArray)[::-1][0:10]]):\n",
      "#         print word + ':' + str(np.sort(medArray)[::-1][k])\n",
      "    \n",
      "        \n",
      "#     print np.sort(meanArray)[::-1][0:10]\n",
      "#     print np.array(vectorizer.get_feature_names())[np.argsort(meanArray)[::-1][0:10]]\n",
      "#     print len(meanArray)\n",
      "    \n",
      "\n",
      "#     medArray = []\n",
      "#     for i in range(len(tempArray[0])):\n",
      "#         medArray.append(np.median(tempArray[np.nonzero(tempArray[:,i]),i]))\n",
      "        \n",
      "#     print medArray\n",
      "    \n",
      "#     print np.median(np.nonzero(tempArray[:,127]))\n",
      "#     print np.median(tempArray[np.nonzero(tempArray[:,127]),127])\n",
      "    \n",
      "#     medArray = []\n",
      "#     for col in range(len(tempArray[0])):\n",
      "#         medArray.append(sorted(tempArray[:,col])[len(tempArray[:,col])/2])\n",
      "#     print medArray\n",
      "#     print type(tempArray)\n",
      "#     print tempArray.shape\n",
      "#     print tempArray\n",
      "#     print len(np.nonzero(tempArray[0,]))\n",
      "#     print tempArray.shape\n",
      "#     tempArray = np.asarray(tempArray)\n",
      "#     medArray = []\n",
      "#     for i in range(tempArray.shape[1] - 1):\n",
      "#         medArray.append(np.median(tempArray[:, i]))\n",
      "        \n",
      "#     print(category + str(medArray[1225]) + str(len(medArray[1225])))\n",
      "#     medArray = np.median(tempArray,axis=0)\n",
      "#     print np.nonzero(medArray)\n",
      "#     print medArray.shape\n",
      "#     print(medArray)\n",
      "#     print medArray\n",
      "#     print(np.nonzero(medArray)[0])\n",
      "#     print type(tempArray)\n",
      "          \n",
      "#     medArray = np.asarray(medArray)\n",
      "#     medArray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "============alt.atheism=============\n",
        "delet:0.0315323859473\n",
        "say:0.0310510311621\n",
        "god:0.0297387960148\n",
        "think:0.0284422200482\n",
        "claim:0.0281925593881\n",
        "just:0.0270684836744\n",
        "post:0.0248549742615\n",
        "moral:0.0242344682493\n",
        "omnipot:0.0230437316415\n",
        "islam:0.0205092481461\n",
        "============comp.graphics=============\n",
        "imag:0.0561626977499\n",
        "graphic:0.047520494563\n",
        "use:0.0359898131419\n",
        "file:0.034260347217\n",
        "version:0.0329343639769\n",
        "ani:0.0324121875363\n",
        "mode:0.0272988864573\n",
        "know:0.0261145323297\n",
        "color:0.0257638303501\n",
        "thank:0.0249823126298\n",
        "============comp.os.ms-windows.misc=============\n",
        "window:0.122943856765"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "dos:0.0476861069417\n",
        "driver:0.0475167971046\n",
        "use:0.0460144462112\n",
        "file:0.0424912879522\n",
        "problem:0.0321198853144\n",
        "mous:0.0291209232999\n",
        "doe:0.0289289446572\n",
        "thank:0.0285587883132\n",
        "tri:0.0276407875913\n",
        "============comp.sys.ibm.pc.hardware=============\n",
        "drive:0.069536452179\n",
        "control:0.0481969565445\n",
        "bus:0.0445950744603\n",
        "ani:0.0400067148093\n",
        "card:0.0394770999994\n",
        "use:0.0383110159012\n",
        "doe:0.0381206689338\n",
        "board:0.0354489118833\n",
        "thank:0.0344790626096\n",
        "switch:0.0325274456092\n",
        "============comp.sys.mac.hardware=============\n",
        "mac:0.0680117000966\n",
        "appl:0.0635912575063\n",
        "drive:0.0497797378912\n",
        "thank:0.035486818521\n",
        "monitor:0.0272586079396\n",
        "doe:0.0268432108011\n",
        "card:0.0266242292528\n",
        "need:0.0266195153965\n",
        "know:0.0259416139284\n",
        "problem:0.0255265522396\n",
        "============comp.windows.x=============\n",
        "use:0.0507439392416"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "file:0.0481005204437\n",
        "window:0.0471457390189\n",
        "widget:0.0418765889678\n",
        "server:0.035908332476\n",
        "display:0.034936920032\n",
        "motif:0.0335043781307\n",
        "program:0.0329730929224\n",
        "thank:0.0328709421918\n",
        "ani:0.0300796301078\n",
        "============misc.forsale=============\n",
        "sale:0.059541299736\n",
        "ship:0.0441834999079\n",
        "new:0.0410237933822\n",
        "offer:0.0385450653011\n",
        "brand:0.0367688357017\n",
        "sell:0.0365091568173\n",
        "condit:0.0341763702779\n",
        "mail:0.032433103361\n",
        "includ:0.0307164938678\n",
        "use:0.0293932998206\n",
        "============rec.autos=============\n",
        "car:0.0882214365172\n",
        "dealer:0.0257112317483\n",
        "ani:0.0248270446254\n",
        "like:0.0238202913195\n",
        "just:0.0217302001597\n",
        "good:0.0216721644616\n",
        "rear:0.0204343750926\n",
        "know:0.0193330373209\n",
        "engin:0.0188491937726\n",
        "think:0.0179500104623\n",
        "============rec.motorcycles=============\n",
        "bike:0.0906207607376"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "like:0.0360495462773\n",
        "ride:0.0336145813546\n",
        "motorcycl:0.0289119879501\n",
        "just:0.0270611267904\n",
        "know:0.0227306670732\n",
        "don:0.0221801578188\n",
        "dod:0.0221211292257\n",
        "helmet:0.0219384299907\n",
        "drunk:0.0201222303637\n",
        "============rec.sport.baseball=============\n",
        "year:0.0370105711878\n",
        "game:0.0346040059737\n",
        "basebal:0.0277210697185\n",
        "player:0.0263730356435\n",
        "cub:0.0256427621553\n",
        "think:0.0244209016465\n",
        "ball:0.0234851008914\n",
        "hit:0.0219975287271\n",
        "era:0.0207539369175\n",
        "whi:0.0206889365105\n",
        "============rec.sport.hockey=============\n",
        "team:0.0707768594509\n",
        "game:0.0700915849306\n",
        "hockey:0.0600443457159\n",
        "player:0.0558281153202\n",
        "play:0.0519908486835\n",
        "playoff:0.0350774068133\n",
        "trade:0.0256112287037\n",
        "fan:0.0249560321608\n",
        "vote:0.0247802756404\n",
        "leaf:0.0247351416478\n",
        "============sci.crypt=============\n",
        "key:0.0906176548087"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "encrypt:0.0657667653855\n",
        "chip:0.0655413309978\n",
        "govern:0.044787275925\n",
        "use:0.0423328095803\n",
        "secur:0.037242828275\n",
        "clipper:0.0357966466864\n",
        "algorithm:0.029558303302\n",
        "nsa:0.0295476075109\n",
        "phone:0.0293073294616\n",
        "============sci.electronics=============\n",
        "use:0.0383571858614\n",
        "chip:0.0323602434344\n",
        "ani:0.0261778197768\n",
        "line:0.0238444941127\n",
        "work:0.0225229607175\n",
        "like:0.0223860716964\n",
        "power:0.0217356251624\n",
        "circuit:0.0204096473092\n",
        "doe:0.019996406316\n",
        "detector:0.0189254940977\n",
        "============sci.med=============\n",
        "pain:0.0312133339271\n",
        "doctor:0.0284258305701\n",
        "know:0.0268055968152\n",
        "seizur:0.0250260895107\n",
        "good:0.0228476520649\n",
        "diseas:0.022042203636\n",
        "use:0.021631685851\n",
        "medic:0.0215344578318\n",
        "ani:0.020925172258\n",
        "think:0.0193844337349\n",
        "============sci.space=============\n",
        "space:0.0672312442212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "orbit:0.0398526088119\n",
        "launch:0.0382719161451\n",
        "nasa:0.0287325452294\n",
        "moon:0.0271427505807\n",
        "satellit:0.0258072215022\n",
        "mission:0.0249873845337\n",
        "project:0.0203339316166\n",
        "spacecraft:0.0197094345803\n",
        "station:0.0195543366403\n",
        "============soc.religion.christian=============\n",
        "god:0.0907198131212\n",
        "christian:0.0668068519033\n",
        "jesus:0.0485048193813\n",
        "believ:0.0394524841961\n",
        "church:0.0342057588237\n",
        "truth:0.0332791849688\n",
        "peopl:0.0296055512783\n",
        "bibl:0.0264307796037\n",
        "christ:0.0263269190487\n",
        "onli:0.0254168498928\n",
        "============talk.politics.guns=============\n",
        "gun:0.0865345980028\n",
        "peopl:0.0415637709442\n",
        "govern:0.0373248850315\n",
        "fbi:0.0310983408447\n",
        "right:0.0257045543254\n",
        "weapon:0.0252394881653\n",
        "don:0.0250524696467\n",
        "like:0.0213910462773\n",
        "kill:0.0202883948525\n",
        "law:0.0197767365402\n",
        "============talk.politics.mideast=============\n",
        "israel:0.0698956331281"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "armenian:0.0578635131313\n",
        "arab:0.0531823831808\n",
        "jew:0.051599669849\n",
        "isra:0.0379622562933\n",
        "peopl:0.0325857846086\n",
        "kill:0.0314028319303\n",
        "palestinian:0.0273619447995\n",
        "turkish:0.0266995595666\n",
        "just:0.0252352324612\n",
        "============talk.politics.misc=============\n",
        "tax:0.0386960518845\n",
        "peopl:0.0345097064423\n",
        "govern:0.028383038018\n",
        "libertarian:0.0272713528997\n",
        "law:0.0270707687203\n",
        "trial:0.0266792383626\n",
        "don:0.0245762066335\n",
        "like:0.0219085062456\n",
        "drug:0.0215535922051\n",
        "legal:0.0214743530883\n",
        "============talk.religion.misc=============\n",
        "christian:0.0525076887266\n",
        "jesus:0.0461883787426\n",
        "god:0.0451517296406\n",
        "kent:0.0270464113055\n",
        "children:0.025505870538\n",
        "law:0.0246341865332\n",
        "fbi:0.0230879747488\n",
        "christ:0.0222226869703\n",
        "did:0.0215697193956\n",
        "belief:0.0198764983069\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array(np.sort(meanArray)[0])[0,]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([ 0.        ,  0.        ,  0.        , ...,  0.03703765,\n",
        "        0.03821608,  0.04724743])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meanArray = X_train[sample[0]].mean(axis=0)\n",
      "np.array(np.argsort(meanArray)[0,np.array(np.sort(meanArray)).shape[1]-11:np.array(np.sort(meanArray)).shape[1]-1])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "array([ 670,  669, 2038, 1256, 2725, 4144, 1238, 4034, 3142, 3961])"
       ]
      }
     ],
     "prompt_number": 78
    }
   ],
   "metadata": {}
  }
 ]
}